# Quick Reference Card (Ralph Pattern)

## ğŸƒ Quick Start

```bash
# First time setup
/issue setup

# For each issue:
/issues              # List open issues
/issue 42            # Load â†’ scope â†’ plan â†’ approve (guided flow)
/implement start     # Create branch, begin loop
/issue close         # After testing verified â†’ create PR
```

## ğŸ“‹ Commands

| Command | Action |
|---------|--------|
| `/issue setup` | Create labels & templates |
| `/issues` | List open issues |
| `/issue N` | Load â†’ scope â†’ plan â†’ approve (full guided flow) |
| `/issue N --quick` | Load issue, skip to status check |
| `/implement` | Execute next failing task |
| `/implement start` | Create branch, start US-001 |
| `/implement loop` | Run task loop in background |
| `/issue close` | Generate report + create PR |
| `/issue close --force` | Skip testing verification |
| `/issue close close` | Report + close issue |

## ğŸ” Issue Scoping

When you load an issue, it's scored 0-10 on completeness:

| Score | Action |
|-------|--------|
| 8-10 | Ready â†’ proceed to `/plan` |
| 5-7 | Ask 1-2 questions |
| 0-4 | Ask up to 3 questions |

**Dimensions scored:** What, Where, Why, Scope, Acceptance (2 pts each)

Use `--quick` to skip scoping for issues already in progress.

## ğŸ·ï¸ Labels

| Label | Meaning |
|-------|---------|
| `AI` | Trigger planning |
| `AI: Planning` | Plan in progress |
| `AI: Approved` | Ready to implement |
| `AI: In Progress` | Being worked on |
| `AI: Testing` | All tasks pass, user testing |
| `AI: Blocked` | Failed 3x, needs human |
| `AI: Review` | PR ready for review |
| `AI: Complete` | Done |

## ğŸ’¬ Issue Comment Prefixes

| Prefix | Purpose |
|--------|---------|
| `## ğŸ“‹ Implementation Plan` | The plan |
| `## ğŸ“ Task Log: US-XXX` | Task result (pass/fail) |
| `## ğŸ” Discovery Note` | Learnings for future tasks |
| `## ğŸ§¾ Compacted Summary` | Periodic context summary |
| `## ğŸª¶ Wisp` | Ephemeral context hint |
| `## ğŸŒ Browser Verification: US-XXX` | Browser verification evidence for UI tasks |
| `## ğŸ” Replan Checkpoint` | Retry-stall checkpoint |
| `## ğŸ§ª Testing Checkpoint` | Request user testing |
| `## ğŸ”§ Debug Session` | Debug attempt |
| `## âœ… Debug Fix Applied` | Debug fix verified |
| `## ğŸš« Debug Blocked` | Debug failed 3x |
| `## ğŸ“Š Final Report` | Final summary |

## ğŸ“„ prd.json Structure

```json
{
  "issueNumber": 42,
  "branchName": "ai/issue-42-feature",
  "memory": {"patterns": []},
  "userStories": [{
    "id": "US-001",
    "title": "Create user schema",
    "requiresBrowserVerification": false,
    "acceptanceCriteria": ["npm run typecheck passes"],
    "verifyCommands": ["npm run typecheck"],
    "passes": false,
    "attempts": 0
  }]
}
```

## ğŸŒ¿ Branch & Commits

- **Branch**: `ai/issue-42-feature-name`
- **Commit**: `feat(US-001): description (#42)`
- **prd.json update**: `chore: update prd.json - US-001 passed (#42)`

## ğŸ”„ The Loop

```
/implement
    â†“
Read prd.json â†’ Find next task where passes=false
    â†“
Execute task
    â†“
Run verifyCommands
    â†“
Pass? â†’ Update prd.json, commit, post Task Log
Fail? â†’ Post Task Log with analysis, retry (max 3x)
    â†“
All pass? â†’ Testing Checkpoint
    â†“
User tests â†’ "Works" / "Issue" / "Later"
    â†“
Works? â†’ /issue close
Issue? â†’ Debug flow (3 attempts max)
Later? â†’ Pause, resume with /implement
```

## ğŸ›¡ï¸ Authoritative Gates

- Task pass/fail is computed by orchestrator verify, not model `<result>` tags.
- `maxTaskAttempts` is enforced from `.issueloop.config.json`.
- Verified task log Event JSON evidence is required by default.
- Event JSON should include `search.queries` evidence.
- Event JSON may include `patterns` for durable memory sync.
- Placeholder patterns in added lines are scanned each iteration.
- UI tasks require browser verification event evidence.
- `execution.gateMode`:
  - `enforce` (default): violations fail the task.
  - `warn`: log violations, continue if verify passes.
- Browser event schema (for required UI tasks):
  - `{"v":1,"type":"browser_verification","issue":42,"taskId":"US-003","taskUid":"tsk_...","tool":"playwright","status":"passed","artifacts":["screenshot:/abs/path.png"],"ts":"<ISO 8601>"}`
- Repeated retries trigger `debugState.status = "replan_required"` and a `## ğŸ” Replan Checkpoint` issue comment.

## ğŸ§  Fresh Context Rule

Each `/implement` = **new session with no memory**

Context comes ONLY from:
- `prd.json` - task definitions, pass/fail
- Issue comments - task logs, learnings
- Git history - committed code

## âœ… Good Acceptance Criteria

```
âœ“ "npm run typecheck passes"
âœ“ "npm run test -- auth passes"
âœ“ "POST /api/users returns 201"
âœ— "Code is clean" (not testable)
âœ— "Works correctly" (vague)
```

## ğŸ›‘ If Blocked (3 failures)

1. Task Log posted with failure analysis
2. Label â†’ `AI: Blocked`
3. Human adds guidance comment
4. Run `/implement` to retry

## ğŸ“ Files

```
.claude/
â”œâ”€â”€ CLAUDE.md              # Project rules
â”œâ”€â”€ rules/
â”‚   â”œâ”€â”€ github-issue-workflow.md
â”‚   â””â”€â”€ planning-guide.md  # Planning methodology
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ issue-setup.md
â”‚   â”œâ”€â”€ issues.md
â”‚   â”œâ”€â”€ issue.md           # Scope + plan + approve flow
â”‚   â”œâ”€â”€ implement.md
â”‚   â””â”€â”€ issue-close.md     # Report + PR creation
â””â”€â”€ scripts/
    â””â”€â”€ implement-loop.sh  # Background task loop script

prd.json                   # Task state (after approval in /issue)
.claude/implement-loop.log # Background loop output (when running)
.claude/implement-loop.pid # Background loop PID (when running)
```
